# src/core/search_algorithms/local.py
"""Local search algorithms for optimization problems in a state-space search framework.

This module implements hill climbing, random-restart hill climbing, hill climbing with sideways moves,
and simulated annealing algorithms. These are designed for problems defined in src.core.problem,
where the goal is to maximize a value function (e.g., optimizing a Boggle board's score or solving
constraint satisfaction problems). Unlike informed search, local search focuses on improving a single
state iteratively, making it suitable for large or complex state spaces.
"""

import math
import random
import sys
from typing import Callable, List, Optional, Tuple
from src.core.problem import Node, Problem
from src.utils.utils import argmax_random_tie, probability

def hill_climbing(problem: Problem) -> Tuple[Node, int, int]:
    """Perform hill climbing to find a state with a high value.

    Starting from the initial state, repeatedly select the neighbor with the highest value until no
    better neighbor exists (a local or global maximum). Based on Figure 4.2 from "Artificial
    Intelligence: A Modern Approach."

    Args:
        problem: A Problem instance defining the initial state, value function, and state transitions.

    Returns:
        A tuple of (node, nodes_visited, path_length):
        - node: The Node at the local/global maximum.
        - nodes_visited: The number of nodes explored during the search.
        - path_length: The number of moves from the initial state to the final state.
    """
    # Initialize with the problem's initial state
    current = Node(problem.initial)
    nodes_visited = 0

    while True:
        # Expand the current node to get all possible neighbors
        neighbors = current.expand(problem)
        if not neighbors:
            break
        # Select the neighbor with the highest value (random tie-breaking)
        neighbor = argmax_random_tie(neighbors, key=lambda node: problem.value(node.state))
        # Stop if no neighbor has a higher value
        if problem.value(neighbor.state) <= problem.value(current.state):
            break
        # Move to the better neighbor
        current = neighbor
        nodes_visited += 1

    return current, nodes_visited, len(current.path())

def hill_climbing_random_restart(
    problem: Problem,
    random_generator: Callable[[], Node],
    k: int = 1000
) -> Tuple[Optional[Node], int, int]:
    """Perform hill climbing with random restarts to find a goal state.

    Run hill climbing from the initial state. If it doesn't reach a goal, perform up to k additional
    hill climbing runs from random starting states (generated by random_generator) until a goal is
    found or k restarts are exhausted.

    Args:
        problem: A Problem instance with initial state, goal test, and value function.
        random_generator: A function that returns a random Node to start a new search.
        k: Maximum number of random restarts (default: 1000).

    Returns:
        A tuple of (node, nodes_visited, path_length):
        - node: The goal Node if found, or None if no solution is found.
        - nodes_visited: The total number of nodes explored across all restarts.
        - path_length: The length of the solution path, or 0 if no solution.
    """
    # Run hill climbing from the initial state
    result, visited, path_len = hill_climbing(problem)
    nodes_visited = visited

    # Return immediately if the initial run finds a goal
    if problem.goal_test(result.state):
        return result, nodes_visited, path_len

    # Perform up to k random restarts
    for _ in range(k):
        # Generate a random starting node
        current = random_generator()
        nodes_visited += 1
        # Run hill climbing from the random node
        result, visited, path_len = hill_climbing(current)
        nodes_visited += visited
        # Return if a goal is found
        if problem.goal_test(result.state):
            return result, nodes_visited, path_len

    # Return failure if no goal is found after k restarts
    return None, nodes_visited, 0

def hill_climbing_sideway(problem: Problem, bound: int = 200) -> Tuple[Node, int, int]:
    """Perform hill climbing with sideways moves to escape plateaus.

    Similar to hill climbing, but allows up to `bound` consecutive moves to neighbors with equal
    value (sideways moves) to escape plateaus. Stops when no better neighbor exists, the bound is
    reached, or no neighbors remain. Based on Figure 4.2 from AIMA.

    Args:
        problem: A Problem instance with initial state, value function, and state transitions.
        bound: Maximum number of consecutive sideways moves allowed (default: 200).

    Returns:
        A tuple of (node, nodes_visited, path_length):
        - node: The Node at the local/global maximum.
        - nodes_visited: The number of nodes explored during the search.
        - path_length: The number of moves from the initial state to the final state.
    """
    current = Node(problem.initial)
    sideways_moves = 0
    nodes_visited = 0

    while True:
        # Expand the current node to get all possible neighbors
        neighbors = current.expand(problem)
        if not neighbors:
            break
        # Select the neighbor with the highest value (random tie-breaking)
        neighbor = argmax_random_tie(neighbors, key=lambda node: problem.value(node.state))
        neighbor_value = problem.value(neighbor.state)
        current_value = problem.value(current.state)

        # Stop if no neighbor has a higher value
        if neighbor_value < current_value:
            break
        # Stop if the sideways move limit is reached
        if neighbor_value == current_value and sideways_moves >= bound:
            break
        # Allow a sideways move if within bound
        elif neighbor_value == current_value:
            sideways_moves += 1
            current = neighbor
            nodes_visited += 1
        # Move to a better neighbor and reset sideways counter
        else:
            current = neighbor
            sideways_moves = 0
            nodes_visited += 1

    return current, nodes_visited, len(current.path())

def exp_schedule(k: float = 20, lam: float = 0.005, limit: int = 100) -> Callable[[int], float]:
    """Generate a temperature schedule for simulated annealing.

    Returns a function that maps time t to a temperature, using an exponential decay schedule:
    T(t) = k * exp(-lam * t) for t < limit, and 0 for t >= limit. Lower temperatures reduce the
    probability of accepting worse states.

    Args:
        k: Initial temperature scaling factor (default: 20).
        lam: Decay rate for the exponential function (default: 0.005).
        limit: Time step at which temperature becomes 0 (default: 100).

    Returns:
        A function that takes a time step (int) and returns a temperature (float).

    Example:
        schedule = exp_schedule(k=20, lam=0.01, limit=200)
        T = schedule(50)  # Returns temperature at t=50
    """
    return lambda t: k * math.exp(-lam * t) if t < limit else 0

def simulated_annealing(
    problem: Problem,
    schedule: Callable[[int], float] = exp_schedule()
) -> Tuple[Node, int, int]:
    """Perform simulated annealing to find a state with a high value.

    Starting from the initial state, iteratively select a random neighbor and accept it if it has a
    higher value or with a probability based on the temperature schedule and value difference.
    Tracks the best state seen and returns it when the temperature reaches 0 or no neighbors remain.
    Based on Figure 4.5 from AIMA.

    Note: Unlike AIMA pseudocode, this returns a Node and additional metrics, not just a state.

    Args:
        problem: A Problem instance with initial state, value function, and state transitions.
        schedule: A function mapping time t to a temperature (default: exp_schedule()).

    Returns:
        A tuple of (node, nodes_visited, path_length):
        - node: The best Node encountered (highest value).
        - nodes_visited: The number of nodes explored during the search.
        - path_length: The number of moves to the best state.
    """
    current = Node(problem.initial)
    best = current
    best_value = problem.value(current.state)
    nodes_visited = 0

    for t in range(sys.maxsize):
        # Get the current temperature
        temperature = schedule(t)
        # Stop when temperature reaches 0, returning the best state
        if temperature == 0:
            return best, nodes_visited, len(best.path())
        # Expand the current node to get neighbors
        neighbors = current.expand(problem)
        if not neighbors:
            return best, nodes_visited, len(best.path())
        # Randomly select a neighbor
        next_choice = random.choice(neighbors)
        # Compute the value difference (positive if better)
        delta_e = problem.value(next_choice.state) - problem.value(current.state)
        # Accept better neighbors or worse ones with probability e^(delta_e/T)
        if delta_e > 0 or probability(math.exp(delta_e / temperature)):
            current = next_choice
            nodes_visited += 1
            # Update best state if current is better
            current_value = problem.value(current.state)
            if current_value > best_value:
                best = current
                best_value = current_value
    # Fallback return (should be unreachable with proper schedule)
    return best, nodes_visited, len(best.path())

def simulated_annealing_full(
    problem: Problem,
    schedule: Callable[[int], float] = exp_schedule()
) -> List[object]:
    """Perform simulated annealing and return all states visited.

    Similar to simulated_annealing, but tracks and returns the sequence of states encountered during
    the search. Useful for analyzing the search trajectory or debugging. Stops when the temperature
    reaches 0 or no neighbors remain.

    Args:
        problem: A Problem instance with initial state, value function, and state transitions.
        schedule: A function mapping time t to a temperature (default: exp_schedule()).

    Returns:
        A list of states (not Nodes) visited during the search, including the final state.
    """
    states = []
    current = Node(problem.initial)

    for t in range(sys.maxsize):
        # Record the current state
        states.append(current.state)
        # Get the current temperature
        temperature = schedule(t)
        # Stop when temperature reaches 0
        if temperature == 0:
            return states
        # Expand the current node to get neighbors
        neighbors = current.expand(problem)
        if not neighbors:
            return states
        # Randomly select a neighbor
        next_choice = random.choice(neighbors)
        # Compute the value difference
        delta_e = problem.value(next_choice.state) - problem.value(current.state)
        # Accept better neighbors or worse ones with probability e^(delta_e/T)
        if delta_e > 0 or probability(math.exp(delta_e / temperature)):
            current = next_choice

    return states